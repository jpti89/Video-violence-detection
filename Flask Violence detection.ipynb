{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43747d51-0831-4049-bbab-f1105b0d1187",
   "metadata": {},
   "source": [
    "# This code generate a Flask Web APP to predict and classify images, detecting if there's Violence or not\n",
    "\n",
    "This codes includes function to create thumbnails of the videos in the dataset.\n",
    "\n",
    "It uses the models generated on the Train_violence_model.ipynb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61909ad8-02d9-47d3-9e0d-d9addbe9f417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necesary libs\n",
    "!pip install Flask\n",
    "!pip install imgaug\n",
    "!pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e51221-df87-4c2d-b28b-d56635303ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used once for creating thumbnails of videos\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Specify the directory containing your videos\n",
    "video_directory = './archive/Real Life Violence Dataset/NonViolence'\n",
    "\n",
    "# Specify the directory where you want to save the thumbnails\n",
    "thumbnail_directory = './archive/Real Life Violence Dataset/NonViolence/thumbnails'\n",
    "\n",
    "# Ensure the thumbnail directory exists\n",
    "if not os.path.exists(thumbnail_directory):\n",
    "    os.makedirs(thumbnail_directory)\n",
    "\n",
    "# Iterate over each file in the video directory\n",
    "for filename in os.listdir(video_directory):\n",
    "    # Check if the file is a video (you might need to adjust the condition based on your video formats)\n",
    "    if filename.endswith(('.mp4', '.avi', '.mkv')):\n",
    "        # Construct the full path to the video file\n",
    "        video_path = os.path.join(video_directory, filename)\n",
    "        \n",
    "        # Construct the output path for the thumbnail\n",
    "        thumbnail_path = os.path.join(thumbnail_directory, filename + '.jpg')\n",
    "        \n",
    "        # Use FFmpeg to generate a thumbnail from the video\n",
    "        # This command extracts a frame at 10 seconds into the video and saves it as a JPEG\n",
    "        subprocess.call(['ffmpeg', '-ss', '00:00:1.000', '-i', video_path, '-vframes', '1', thumbnail_path])\n",
    "\n",
    "print(\"Thumbnails generated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb96b371-337e-47ea-8749-b6613278c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Extract frames from videos\n",
    "import cv2\n",
    "import os\n",
    "import imageio\n",
    "import imgaug.augmenters as iaa\n",
    "import imgaug as ia\n",
    "\n",
    "IMG_SIZE = 128\n",
    "ColorChannels = 3\n",
    "\n",
    "def video_to_frames(video):\n",
    "    vidcap = cv2.VideoCapture(video)\n",
    "\n",
    "    import math\n",
    "    rate = math.floor(vidcap.get(3))\n",
    "    count = 0\n",
    "\n",
    "    ImageFrames = []\n",
    "    while vidcap.isOpened():\n",
    "        ID = vidcap.get(1)\n",
    "        success, image = vidcap.read()\n",
    "\n",
    "        if success:\n",
    "            # skipping frames to avoid duplications\n",
    "            if (ID % 7 == 0):\n",
    "                rgb_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                resized = cv2.resize(rgb_img, (IMG_SIZE, IMG_SIZE))\n",
    "                ImageFrames.append(resized)\n",
    "\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    vidcap.release()\n",
    "\n",
    "    return ImageFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceed7535-a92e-4452-8a01-cfe95b98396b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jpti\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jpti\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jpti\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load trained model\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f422fce-0671-4c09-94fe-3e4536d31f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_max(video_name,confidence):\n",
    "    filen = video_name.split(\"\\\\\",2)[1]\n",
    "    v_nv = filen.split(\"_\")[0]\n",
    "    if v_nv == \"NV\":\n",
    "        return np.average(confidence)\n",
    "    elif v_nv == \"V\":\n",
    "        return max(confidence)\n",
    "\n",
    "def with_moviepy(filename):\n",
    "    from moviepy.editor import VideoFileClip\n",
    "    clip = VideoFileClip(filename)\n",
    "    duration       = clip.duration\n",
    "    return duration\n",
    "\n",
    "def newest(path):\n",
    "    files = os.listdir(path)\n",
    "    paths = [os.path.join(path, basename) for basename in files]\n",
    "    return max(paths, key=os.path.getctime)\n",
    "\n",
    "def record(out):\n",
    "    global rec_frame\n",
    "    while(rec):\n",
    "        time.sleep(0.05)\n",
    "        out.write(rec_frame)\n",
    "\n",
    "def gen_frames():  # generate frame by frame from camera\n",
    "    global out, capture,rec_frame\n",
    "    while True:\n",
    "        success, frame = camera.read() \n",
    "        if success:\n",
    "            if(capture):\n",
    "                capture=0\n",
    "                now = datetime.datetime.now()\n",
    "                p = os.path.sep.join(['shots', \"shot_{}.png\".format(str(now).replace(\":\",''))])\n",
    "                cv2.imwrite(p, frame)\n",
    "            \n",
    "            if(rec):\n",
    "                rec_frame=frame\n",
    "                frame= cv2.putText(cv2.flip(frame,1),\"Recording...\", (0,25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255),4)\n",
    "                frame=cv2.flip(frame,1)\n",
    "            \n",
    "            try:\n",
    "                ret, buffer = cv2.imencode('.jpg', cv2.flip(frame,1))\n",
    "                frame = buffer.tobytes()\n",
    "                yield (b'--frame\\r\\n'\n",
    "                       b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "            except Exception as e:\n",
    "                pass\n",
    "                \n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e4c20ab-5715-4609-9f3f-4dd8b3eeb467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://localhost:9000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [23/Apr/2024 03:20:14] \"GET /Youtube_form HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Apr/2024 03:20:29] \"POST /Youtube_form HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Apr/2024 03:20:29] \"GET /static/inference.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Apr/2024 03:20:32] \"POST /Youtube_train HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Violence\n",
      "Held his own He wins a 5 vs 1 fight and gets ovation 6th Street Austin TX.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Apr/2024 03:20:40] \"GET /Youtube_form HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Apr/2024 03:20:50] \"POST /Youtube_form HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Apr/2024 03:20:50] \"GET /static/inference.jpeg HTTP/1.1\" 200 -\n",
      "[2024-04-23 03:20:57,405] ERROR in app: Exception on /Youtube_train [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jpti\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 2529, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jpti\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1825, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jpti\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1823, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jpti\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1799, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jpti\\AppData\\Local\\Temp\\ipykernel_31248\\1568644336.py\", line 112, in Youtube_train\n",
      "    os.rename(os.path.join(\"./\",filename), dest)\n",
      "FileExistsError: [WinError 183] No se puede crear un archivo que ya existe: './Held his own He wins a 5 vs 1 fight and gets ovation 6th Street Austin TX.mp4' -> './retrain\\\\Violence\\\\Held his own He wins a 5 vs 1 fight and gets ovation 6th Street Austin TX.mp4'\n",
      "127.0.0.1 - - [23/Apr/2024 03:20:57] \"POST /Youtube_train HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Violence\n",
      "Held his own He wins a 5 vs 1 fight and gets ovation 6th Street Austin TX.mp4\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, Response, redirect, url_for\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "from pytube import YouTube\n",
    "from pytube.innertube import _default_clients\n",
    "import random\n",
    "import datetime, time\n",
    "import os, sys\n",
    "from threading import Thread\n",
    "global capture,rec_frame,rec, out \n",
    "capture=0\n",
    "rec=0\n",
    "\n",
    "_default_clients[\"ANDROID_MUSIC\"] = _default_clients[\"ANDROID_CREATOR\"]\n",
    "\n",
    "thumbnails = os.path.join('static','thumbnails')\n",
    "videos = os.path.join('static')\n",
    "template_dir = os.path.abspath('./templates')\n",
    "app = Flask(__name__, template_folder=template_dir)\n",
    "app.config['UPLOAD_FOLDER'] = thumbnails\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def list_videos():\n",
    "    #List random file from directory\n",
    "    video_directory = './static/'\n",
    "    all_files = os.listdir(video_directory)\n",
    "    video_files = [f for f in all_files if f.endswith(('.mp4', '.avi', '.mkv'))]\n",
    "    random_videos = random.sample(video_files, min(1, len(video_files)))\n",
    "    full_filename = os.path.join(app.config['UPLOAD_FOLDER'], random_videos[0] + '.jpg')\n",
    "    full_filename_video = os.path.join(videos, random_videos[0])\n",
    "\n",
    "    all_frames = len(video_to_frames(full_filename_video))\n",
    "    result = []\n",
    "    for i in range(all_frames):\n",
    "        \n",
    "        image_file = video_to_frames(full_filename_video)[i]\n",
    "        im = Image.fromarray(image_file)\n",
    "        im.save(\"inference.jpeg\")\n",
    "        \n",
    "        img_width, img_height = 128, 128\n",
    "        img = image.load_img(\"inference.jpeg\", target_size = (img_width, img_height))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis = 0)\n",
    "        result.append(model.predict(img))\n",
    "        \n",
    "    return render_template('videos.html', videos=random_videos, images = full_filename, detection = avg_max(full_filename_video,result))\n",
    "\n",
    "@app.route('/select_video', methods=['POST'])\n",
    "def select_video():\n",
    "    #List random file from directory\n",
    "    video_directory = './static'\n",
    "    all_files = os.listdir(video_directory)\n",
    "    video_files = [f for f in all_files if f.endswith(('.mp4', '.avi', '.mkv'))]\n",
    "    random_videos = random.sample(video_files, min(1, len(video_files)))\n",
    "    full_filename = os.path.join(app.config['UPLOAD_FOLDER'], random_videos[0] + '.jpg')\n",
    "    full_filename_video = os.path.join(videos, random_videos[0])\n",
    "\n",
    "    all_frames = len(video_to_frames(full_filename_video))\n",
    "    result = []\n",
    "    for i in range(all_frames):\n",
    "        \n",
    "        image_file = video_to_frames(full_filename_video)[i]\n",
    "        im = Image.fromarray(image_file)\n",
    "        im.save(\"inference.jpeg\")\n",
    "        \n",
    "        img_width, img_height = 128, 128\n",
    "        img = image.load_img(\"inference.jpeg\", target_size = (img_width, img_height))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis = 0)\n",
    "        result.append(model.predict(img))\n",
    "        \n",
    "    return render_template('videos.html', videos=random_videos, images = full_filename, detection = avg_max(full_filename_video,result))\n",
    "\n",
    "@app.route('/Youtube_form', methods=['GET', 'POST'])\n",
    "def Youtube_form():\n",
    "    if request.method == 'POST':\n",
    "        yt = YouTube(request.form['link'], use_oauth=True, allow_oauth_cache=True)\n",
    "        new_video = yt.streams.first().download('')\n",
    "        ytvideo = new_video.split(\"\\\\\",5)[5]\n",
    "        ffmpeg_extract_subclip(ytvideo, np.int32(request.form['time']), np.int32(request.form['time'])+5, targetname=\"video.mp4\")\n",
    "        all_frames = len(video_to_frames(\"video.mp4\"))\n",
    "        result = []\n",
    "        for i in range(all_frames):\n",
    "            \n",
    "            image_file = video_to_frames(\"video.mp4\")[i]\n",
    "            im = Image.fromarray(image_file)\n",
    "            im.save(\"./static/inference.jpeg\")\n",
    "            \n",
    "            img_width, img_height = 128, 128\n",
    "            img = image.load_img(\"./static/inference.jpeg\", target_size = (img_width, img_height))\n",
    "            img = image.img_to_array(img)\n",
    "            img = np.expand_dims(img, axis = 0)\n",
    "            result.append(model.predict(img))\n",
    "\n",
    "        return render_template('Youtube_results.html', videos=ytvideo, images = \"./inference.jpeg\", detection = np.average(result))\n",
    "     \n",
    "    return render_template('Youtube_form.html')\n",
    "\n",
    "@app.route('/Youtube_train', methods=['GET', 'POST'])\n",
    "def Youtube_train():\n",
    "    if request.method == 'POST':\n",
    "        video_type = ''.join(list(request.form.listvalues())[1])\n",
    "        filename = request.form['video_name']\n",
    "        dest = os.path.join(\"./retrain\",video_type,filename)\n",
    "        os.rename(os.path.join(\"./\",filename), dest)\n",
    "                             \n",
    "        return render_template('Youtube_train.html', path = dest)\n",
    "\n",
    "@app.route('/streaming',methods=['GET', 'POST'])\n",
    "def tasks():\n",
    "    global switch,camera,result\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    if request.method == 'POST':\n",
    "        if request.form.get('click') == 'Capture':\n",
    "            global capture\n",
    "            capture=1\n",
    "            img_width, img_height = 128, 128\n",
    "            img = image.load_img(newest(\"./shots\"), target_size = (img_width, img_height))\n",
    "            img = image.img_to_array(img)\n",
    "            img = np.expand_dims(img, axis = 0)\n",
    "            result = model.predict(img)\n",
    "            \n",
    "        elif  request.form.get('rec') == 'Start/Stop Recording':\n",
    "            global rec, out, rec_frame\n",
    "            rec= not rec\n",
    "            if(rec):\n",
    "                now=datetime.datetime.now() \n",
    "                fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "                out = cv2.VideoWriter('./recordings/vid_{}.avi'.format(str(now).replace(\":\",'')), fourcc, 20.0, (640, 480))\n",
    "                #Start new thread for recording the video\n",
    "                thread = Thread(target = record, args=[out,])\n",
    "                thread.start()\n",
    "            elif(rec==False):\n",
    "                out.release()\n",
    "                all_frames = len(video_to_frames(newest(\"./recordings\")))\n",
    "                result = []\n",
    "                for i in range(all_frames):\n",
    "                    \n",
    "                    image_file = video_to_frames(newest(\"./recordings\"))[i]\n",
    "                    im = Image.fromarray(image_file)\n",
    "                    im.save(\"./static/inference.jpeg\")\n",
    "                    \n",
    "                    img_width, img_height = 128, 128\n",
    "                    img = image.load_img(\"./static/inference.jpeg\", target_size = (img_width, img_height))\n",
    "                    img = image.img_to_array(img)\n",
    "                    img = np.expand_dims(img, axis = 0)\n",
    "                    result.append(model.predict(img))\n",
    "        \n",
    "        return render_template('streaming.html', detection = np.average(result))\n",
    "    return render_template('streaming.html')\n",
    "    \n",
    "@app.route('/video_feed')\n",
    "def video_feed():\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    return Response(gen_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "@app.route('/rtsp_streaming',methods=['GET', 'POST'])\n",
    "def tasks_rtsp():\n",
    "    global switch,camera,result\n",
    "    # Other feeds https://g33ktricks.blogspot.com/p/the-rtsp-real-time-streaming-protocol.html\n",
    "    camera = cv2.VideoCapture('http://webcam01.ecn.purdue.edu/mjpg/video.mjpg')\n",
    "    if request.method == 'POST':\n",
    "        if request.form.get('click') == 'Capture':\n",
    "            global capture\n",
    "            capture=1\n",
    "            img_width, img_height = 128, 128\n",
    "            img = image.load_img(newest(\"./shots\"), target_size = (img_width, img_height))\n",
    "            img = image.img_to_array(img)\n",
    "            img = np.expand_dims(img, axis = 0)\n",
    "            result = model.predict(img)\n",
    "            \n",
    "        elif  request.form.get('rec') == 'Start/Stop Recording':\n",
    "            global rec, out, rec_frame\n",
    "            rec= not rec\n",
    "            if(rec):\n",
    "                now=datetime.datetime.now() \n",
    "                fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "                out = cv2.VideoWriter('./recordings/vid_{}.avi'.format(str(now).replace(\":\",'')), fourcc, 20.0, (640, 480))\n",
    "                #Start new thread for recording the video\n",
    "                thread = Thread(target = record, args=[out,])\n",
    "                thread.start()\n",
    "            elif(rec==False):\n",
    "                out.release()\n",
    "                all_frames = len(video_to_frames(newest(\"./recordings\")))\n",
    "                result = []\n",
    "                for i in range(all_frames):\n",
    "                    \n",
    "                    image_file = video_to_frames(newest(\"./recordings\"))[i]\n",
    "                    im = Image.fromarray(image_file)\n",
    "                    im.save(\"./static/inference.jpeg\")\n",
    "                    \n",
    "                    img_width, img_height = 128, 128\n",
    "                    img = image.load_img(\"./static/inference.jpeg\", target_size = (img_width, img_height))\n",
    "                    img = image.img_to_array(img)\n",
    "                    img = np.expand_dims(img, axis = 0)\n",
    "                    result.append(model.predict(img))\n",
    "        \n",
    "        return render_template('streaming_rtsp.html', detection = np.average(result))\n",
    "    return render_template('streaming_rtsp.html')\n",
    "    \n",
    "@app.route('/video_feed_rtsp')\n",
    "def video_feed_rtsp():\n",
    "    # Other feeds https://g33ktricks.blogspot.com/p/the-rtsp-real-time-streaming-protocol.html\n",
    "    camera = cv2.VideoCapture('http://webcam01.ecn.purdue.edu/mjpg/video.mjpg')\n",
    "    return Response(gen_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from werkzeug.serving import run_simple\n",
    "    run_simple('localhost', 9000, app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9b6b1b-1781-40af-af84-585e1b77a1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a6ec2a-2ec1-4653-ad27-85e5b8109517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e66c1d8-e3be-460f-b87e-b803f17ee263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
